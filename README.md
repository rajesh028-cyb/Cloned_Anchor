# ANCHOR - Real-Time Voice AI Agent ğŸ™ï¸ğŸ›¡ï¸

**A sub-500ms latency voice AI that maintains strict persona boundaries and cannot be jailbroken.**

---

## âš¡ Quick Start (v2 - Refactored)

```bash
# Automated setup
setup_windows.bat     # Windows
./setup_linux.sh      # Linux/macOS

# Then run
python run_anchor.py
```

**All files now use `config_v2` consistently. No import errors. Ready to run.**

---

# Original Project Documentation

## Voice AI Agent - Scammer Deterrent

A real-time voice AI agent that talks to scammers over an audio stream, designed for ultra-low latency (<500ms response time).

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Microphone â”‚â”€â”€â”€â–¶â”‚  Silero VAD â”‚â”€â”€â”€â–¶â”‚  Whisper    â”‚â”€â”€â”€â–¶â”‚   State     â”‚
â”‚   Input     â”‚    â”‚  Detection  â”‚    â”‚  ASR        â”‚    â”‚  Machine    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                                 â”‚
                                                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Speaker   â”‚â—€â”€â”€â”€â”‚  Coqui TTS  â”‚â—€â”€â”€â”€â”‚  Local LLM  â”‚â—€â”€â”€â”€â”‚   Response  â”‚
â”‚   Output    â”‚    â”‚  Synthesis  â”‚    â”‚  (Phi/Llama)â”‚    â”‚  Generator  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Pipeline Flow

1. **VAD (Voice Activity Detection)** - Silero VAD detects when speech starts/ends
2. **ASR (Automatic Speech Recognition)** - Whisper.cpp transcribes the audio
3. **State Machine** - Analyzes transcript and selects behavior state:
   - `CLARIFY` - Ask scammer to repeat/explain
   - `CONFUSE` - Act confused, give off-topic responses
   - `STALL` - Delay with filler words (plays preloaded audio)
   - `EXTRACT` - Subtly probe for scammer information
   - `DEFLECT` - Change subject, avoid giving information
4. **LLM** - Generates short response based on state
5. **TTS** - Converts response to speech
6. **Playback** - Plays audio through speakers

## Project Structure

```
Anchor/
â”œâ”€â”€ main.py           # Main orchestrator
â”œâ”€â”€ config.py         # Configuration settings
â”œâ”€â”€ vad.py            # Voice Activity Detection (Silero)
â”œâ”€â”€ asr.py            # Speech Recognition (Whisper)
â”œâ”€â”€ state_machine.py  # Behavior state machine
â”œâ”€â”€ llm.py            # Local LLM for responses
â”œâ”€â”€ tts.py            # Text-to-Speech (Coqui)
â”œâ”€â”€ audio_utils.py    # Audio recording/playback
â”œâ”€â”€ requirements.txt  # Python dependencies
â”œâ”€â”€ models/           # Model files (download separately)
â”‚   â”œâ”€â”€ ggml-base.en.bin
â”‚   â””â”€â”€ phi-2.gguf
â””â”€â”€ audio/
    â””â”€â”€ fillers/      # Preloaded filler audio
        â”œâ”€â”€ uhh_wait_beta.wav
        â”œâ”€â”€ hmm_let_me_think.wav
        â””â”€â”€ one_moment.wav
```

## Installation

### 1. Install Python dependencies

```bash
pip install -r requirements.txt
```

### 2. Download models

**Whisper model:**
```bash
mkdir -p models
# Download from https://huggingface.co/ggerganov/whisper.cpp
wget -O models/ggml-base.en.bin https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.en.bin
```

**LLM model (Phi-2 or similar):**
```bash
# Download from https://huggingface.co/TheBloke/phi-2-GGUF
wget -O models/phi-2.gguf https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_M.gguf
```

**Alternative: Use Ollama**
```bash
# Install Ollama from https://ollama.ai
ollama pull phi
```

### 3. Create filler audio files

Place `.wav` files in `audio/fillers/`:
- `uhh_wait_beta.wav`
- `hmm_let_me_think.wav`
- `one_moment.wav`

## Usage

```bash
python main.py
```

Press `Ctrl+C` to stop.

## Configuration

Edit `config.py` to customize:

- **Audio settings**: Sample rate, chunk size
- **VAD settings**: Speech detection thresholds
- **LLM settings**: Model path, temperature, max tokens
- **TTS settings**: Voice model selection
- **Blocked patterns**: Regex patterns to filter from responses

## Safety Features

- **No sensitive data generation**: LLM is blocked from generating phone numbers, OTPs, PINs, SSNs
- **State machine control**: Behavior is controlled by rules, not the LLM
- **Response sanitization**: All outputs are filtered through regex patterns

## Performance Optimization

Target: <500ms end-to-end latency

- Use `faster-whisper` with int8 quantization
- Use small LLM (Phi-2) with Q4 quantization
- Preload filler audio for instant playback
- Use streaming where possible

## Troubleshooting

### No audio input detected
- Check microphone permissions
- Verify PyAudio installation: `pip install pyaudio`
- On Linux, install portaudio: `sudo apt install portaudio19-dev`

### High latency
- Use smaller models (base.en for Whisper)
- Reduce LLM max_tokens
- Enable GPU acceleration if available

### TTS not working
- Install Coqui TTS: `pip install TTS`
- Fallback to pyttsx3: `pip install pyttsx3`

## License

MIT License - Use responsibly and ethically.
